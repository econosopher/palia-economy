{"nbformat_minor": 2, "cells": [{"source": ["# Palia Charts\n", "Self-contained notebook with embedded chart cells.\n", "\n", "Prereqs:\n", "- Run your standard Cell 1 SQL flow first to produce `df_daily`.\n", "- Then run this notebook top-to-bottom.\n"], "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["\"\"\"\n", "Lightweight shared style helpers for charts.\n", "\n", "Safe to import from other cell scripts or `%run` first in a notebook.\n", "\"\"\"\n", "\n", "from __future__ import annotations\n", "\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "from matplotlib.ticker import PercentFormatter\n", "\n", "\n", "def ensure_theme() -> None:\n", "    \"\"\"Apply a clean, modern Seaborn theme suitable for notebooks and exports.\"\"\"\n", "    sns.set_theme(style=\"whitegrid\", context=\"talk\")\n", "\n", "\n", "def percent_axis(ax: plt.Axes, axis: str = \"y\", decimals: int = 0) -> None:\n", "    \"\"\"Format the given axis as a percentage for values in [0,1].\"\"\"\n", "    fmt = PercentFormatter(xmax=1.0, decimals=decimals)\n", "    if axis.lower() == \"y\":\n", "        ax.yaxis.set_major_formatter(fmt)\n", "    else:\n", "        ax.xaxis.set_major_formatter(fmt)\n", "\n"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["#!/usr/bin/env python3\n", "# -*- coding: utf-8 -*-\n", "\n", "\"\"\"\n", "Notebook Cell 2 \u2014 In-memory summary.\n", "\n", "Use in a notebook by either:\n", "- Pasting this whole file into Cell 2 and running it (recommended). It will\n", "  resolve `df_daily` (or `_sqldf`/`sdf_daily`), compute `summary`, print\n", "  shapes, and show a preview automatically.\n", "- Or importing `process_summary_inline()` / `run_summary_cell()` and calling\n", "  them yourself.\n", "\"\"\"\n", "\n", "import pandas as pd\n", "import numpy as np\n", "from typing import Any\n", "\n", "\n", "def process_summary_inline(kpi_agg: pd.DataFrame) -> pd.DataFrame:\n", "    df = kpi_agg.copy()\n", "\n", "    # Coerce likely numeric columns\n", "    numeric_cols = [\n", "        \"new_users\",\"new_customers\",\"daily_revenue\",\"daily_transactions\",\n", "        \"daily_active_users\",\"daily_active_customers\",\"daily_payers\",\n", "        \"prior_day_active_users\",\"d_over_d_returning_users\",\n", "        \"prior_day_payers\",\"d_over_d_returning_payers\",\n", "        \"weekly_active_users\",\"prior_week_active_users\",\"w_over_w_returning_users\",\n", "        \"weekly_active_customers\",\"weekly_payers\",\n", "        \"monthly_active_users\",\"prior_month_active_users\",\"m_over_m_returning_users\",\n", "        \"monthly_active_customers\",\"monthly_payers\",\n", "        \"d7_regulars\",\"d30_regulars\",\"weekly_regulars\",\"monthly_regulars\",\n", "        \"prior_day_active_customers\",\"d_over_d_returning_customers\",\n", "        \"prior_week_active_customers\",\"w_over_w_returning_customers\",\n", "        \"prior_week_payers\",\"w_over_w_returning_payers\",\n", "        \"prior_month_active_customers\",\"m_over_m_returning_customers\",\n", "        \"prior_month_payers\",\"m_over_m_returning_payers\",\n", "    ]\n", "    for c in numeric_cols:\n", "        if c in df.columns:\n", "            df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0)\n", "\n", "    # Dates and labels\n", "    df[\"metric_date_dt\"] = pd.to_datetime(df[\"metric_date\"], errors=\"coerce\") if \"metric_date\" in df.columns else pd.to_datetime([])\n", "    df = df.sort_values(\"metric_date_dt\", ascending=True)\n", "    df[\"day_of_week\"] = df[\"metric_date_dt\"].dt.strftime(\"%a\")\n", "    df[\"date\"] = df[\"metric_date_dt\"].dt.strftime(\"%m/%d\")\n", "    df[\"week_start\"] = df[\"metric_date_dt\"].dt.to_period(\"W\").dt.start_time\n", "    df[\"month_start\"] = df[\"metric_date_dt\"].dt.to_period(\"M\").dt.start_time\n", "\n", "    # Consistent aliases\n", "    df[\"daily_new_users\"] = df.get(\"new_users\", 0)\n", "    df[\"daily_new_customers\"] = df.get(\"new_customers\", 0)\n", "\n", "    # Safe division\n", "    def _as_series(x):\n", "        # Avoid pandas ABC isinstance checks (can recurse in some environments)\n", "        try:\n", "            _ = x.index  # Series-like objects have .index\n", "            return x\n", "        except Exception:\n", "            return pd.Series([x] * len(df), index=df.index)\n", "\n", "    def safe_div(a, b):\n", "        a = _as_series(a)\n", "        b = _as_series(b)\n", "        a_arr = pd.to_numeric(a, errors=\"coerce\").to_numpy(dtype=\"float64\", copy=False)\n", "        b_arr = pd.to_numeric(b, errors=\"coerce\").to_numpy(dtype=\"float64\", copy=False)\n", "        with np.errstate(divide='ignore', invalid='ignore'):\n", "            res = np.divide(a_arr, b_arr, out=np.full_like(a_arr, np.nan, dtype=\"float64\"), where=b_arr != 0)\n", "        return pd.Series(res, index=df.index)\n", "\n", "    # Simple derivations & rates\n", "    df[\"dau_minus_new\"] = df.get(\"daily_active_users\", 0) - df.get(\"daily_new_users\", 0)\n", "    df[\"daily_customer_rate\"] = safe_div(df.get(\"daily_active_customers\", 0), df.get(\"daily_active_users\", 0))\n", "    df[\"daily_user_payer_rate\"] = safe_div(df.get(\"daily_payers\", 0), df.get(\"daily_active_users\", 0))\n", "    df[\"daily_customer_payer_rate\"] = safe_div(df.get(\"daily_payers\", 0), df.get(\"daily_active_customers\", 0))\n", "\n", "    # New users -> new customers conversions\n", "    df[\"weekly_new_users\"] = df.groupby(\"week_start\")[\"daily_new_users\"].transform(\"cumsum\")\n", "    df[\"monthly_new_users\"] = df.groupby(\"month_start\")[\"daily_new_users\"].transform(\"cumsum\")\n", "    df[\"weekly_new_customers\"] = df.groupby(\"week_start\")[\"daily_new_customers\"].transform(\"cumsum\")\n", "    df[\"monthly_new_customers\"] = df.groupby(\"month_start\")[\"daily_new_customers\"].transform(\"cumsum\")\n", "    df[\"daily_new_user_to_customer_rate\"] = safe_div(df[\"daily_new_customers\"], df[\"daily_new_users\"])\n", "    df[\"weekly_new_user_to_customer_rate\"] = safe_div(df[\"weekly_new_customers\"], df[\"weekly_new_users\"])\n", "    df[\"monthly_new_user_to_customer_rate\"] = safe_div(df[\"monthly_new_customers\"], df[\"monthly_new_users\"])\n", "\n", "    # Revenue metrics\n", "    df[\"daily_arpu\"] = safe_div(df.get(\"daily_revenue\", 0.0), df.get(\"daily_active_users\", 0))\n", "    df[\"daily_arppu\"] = safe_div(df.get(\"daily_revenue\", 0.0), df.get(\"daily_payers\", 0))\n", "    df[\"daily_arpc\"] = safe_div(df.get(\"daily_revenue\", 0.0), df.get(\"daily_active_customers\", 0))\n", "    if \"daily_revenue\" in df.columns:\n", "        df[\"weekly_revenue\"] = df.groupby(\"week_start\")[\"daily_revenue\"].transform(\"cumsum\")\n", "        df[\"monthly_revenue\"] = df.groupby(\"month_start\")[\"daily_revenue\"].transform(\"cumsum\")\n", "        # Weekly/Monthly ARPU/ARPPU/ARPC\n", "        if \"weekly_active_users\" in df.columns:\n", "            df[\"weekly_arpu\"] = safe_div(df[\"weekly_revenue\"], df.get(\"weekly_active_users\", 0))\n", "        if \"weekly_payers\" in df.columns:\n", "            df[\"weekly_arppu\"] = safe_div(df[\"weekly_revenue\"], df.get(\"weekly_payers\", 0))\n", "        if \"weekly_active_customers\" in df.columns:\n", "            df[\"weekly_arpc\"] = safe_div(df[\"weekly_revenue\"], df.get(\"weekly_active_customers\", 0))\n", "        if \"monthly_active_users\" in df.columns:\n", "            df[\"monthly_arpu\"] = safe_div(df[\"monthly_revenue\"], df.get(\"monthly_active_users\", 0))\n", "        if \"monthly_payers\" in df.columns:\n", "            df[\"monthly_arppu\"] = safe_div(df[\"monthly_revenue\"], df.get(\"monthly_payers\", 0))\n", "        if \"monthly_active_customers\" in df.columns:\n", "            df[\"monthly_arpc\"] = safe_div(df[\"monthly_revenue\"], df.get(\"monthly_active_customers\", 0))\n", "\n", "    # Retention rates\n", "    df[\"dod_retention\"] = safe_div(df.get(\"d_over_d_returning_users\", 0), df.get(\"prior_day_active_users\", 0))\n", "    df[\"wow_retention\"] = safe_div(df.get(\"w_over_w_returning_users\", 0), df.get(\"prior_week_active_users\", 0))\n", "    df[\"mom_retention\"] = safe_div(df.get(\"m_over_m_returning_users\", 0), df.get(\"prior_month_active_users\", 0))\n", "    df[\"dod_payer_retention\"] = safe_div(df.get(\"d_over_d_returning_payers\", 0), df.get(\"prior_day_payers\", 0))\n", "    df[\"wow_payer_retention\"] = safe_div(df.get(\"w_over_w_returning_payers\", 0), df.get(\"prior_week_payers\", 0))\n", "    df[\"mom_payer_retention\"] = safe_div(df.get(\"m_over_m_returning_payers\", 0), df.get(\"prior_month_payers\", 0))\n", "    df[\"dod_customer_retention\"] = safe_div(df.get(\"d_over_d_returning_customers\", 0), df.get(\"prior_day_active_customers\", 0))\n", "    df[\"wow_customer_retention\"] = safe_div(df.get(\"w_over_w_returning_customers\", 0), df.get(\"prior_week_active_customers\", 0))\n", "    df[\"mom_customer_retention\"] = safe_div(df.get(\"m_over_m_returning_customers\", 0), df.get(\"prior_month_active_customers\", 0))\n", "\n", "    # Regular shares\n", "    if \"d7_regulars\" in df.columns:\n", "        df[\"d7_regular_share\"] = safe_div(df[\"d7_regulars\"], df.get(\"daily_active_users\", 0))\n", "    if \"d30_regulars\" in df.columns:\n", "        df[\"d30_regular_share\"] = safe_div(df[\"d30_regulars\"], df.get(\"daily_active_users\", 0))\n", "    # DAU shares (stickiness)\n", "    if \"weekly_active_users\" in df.columns:\n", "        df[\"dau_wau_share\"] = safe_div(df.get(\"daily_active_users\", 0), df[\"weekly_active_users\"])\n", "    if \"monthly_active_users\" in df.columns:\n", "        df[\"dau_mau_share\"] = safe_div(df.get(\"daily_active_users\", 0), df[\"monthly_active_users\"])\n", "\n", "    # Cohort conversion rates and ARPU/ARPC by horizon (if present from SQL)\n", "    if \"cohort_size\" in df.columns:\n", "        for h in (1, 7, 30, 60, 90):\n", "            conv_col = f\"cohort_d{h}_converted\"\n", "            rev_col = f\"cohort_d{h}_revenue\"\n", "            if conv_col in df.columns:\n", "                df[f\"cohort_d{h}_conversion_rate\"] = safe_div(df[conv_col], df[\"cohort_size\"]) \n", "            if rev_col in df.columns:\n", "                df[f\"cohort_d{h}_arpu\"] = safe_div(df[rev_col], df[\"cohort_size\"]) \n", "                if conv_col in df.columns:\n", "                    df[f\"cohort_d{h}_arpc\"] = safe_div(df[rev_col], df[conv_col]) \n", "\n", "    return df.sort_values(\"metric_date_dt\", ascending=False).fillna(0)\n", "\n", "\n", "def run_summary_cell(df_daily: Any) -> pd.DataFrame:\n", "    \"\"\"Ensure pandas input, compute summary, print shapes, and display a preview.\n", "\n", "    - Accepts a pandas DataFrame or a Spark DataFrame (with toPandas()).\n", "    - Prints df/summary shapes for quick sanity.\n", "    - Displays a 5-row preview of the summary.\n", "    - Returns the summary DataFrame.\n", "    \"\"\"\n", "    # Spark \u2192 pandas if needed\n", "    if hasattr(df_daily, \"toPandas\"):\n", "        df_daily = df_daily.toPandas()\n", "\n", "    if not isinstance(df_daily, pd.DataFrame):\n", "        raise TypeError(\"df_daily must be a pandas DataFrame or Spark DataFrame with toPandas().\")\n", "\n", "    print(f\"df_daily rows: {len(df_daily)} | cols: {len(df_daily.columns)}\")\n", "    summary = process_summary_inline(df_daily)\n", "    print(f\"summary rows: {len(summary)} | cols: {len(summary.columns)}\")\n", "\n", "    # Preview with robust fallbacks (some notebook envs have custom display behavior)\n", "    try:\n", "        try:\n", "            from IPython.display import display as ipy_display  # type: ignore\n", "            ipy_display(summary.head(5))\n", "        except Exception:\n", "            # Non-notebook or display unavailable\n", "            print(summary.head(5).to_string(index=False))\n", "    except RecursionError:\n", "        # Rarely, some environments can trigger deep recursion in display; fallback to plain text\n", "        try:\n", "            print(summary.head(5).to_string(index=False))\n", "        except Exception:\n", "            print(\"Preview unavailable due to environment display recursion.\")\n", "\n", "    return summary\n", "\n", "\n", "def _resolve_df_daily() -> pd.DataFrame:\n", "    \"\"\"Resolve df_daily from common notebook patterns: df_daily, _sqldf, sdf_daily.\"\"\"\n", "    g = globals()\n", "    if 'df_daily' in g and not hasattr(g['df_daily'], 'toPandas'):\n", "        # Assume plain pandas if it doesn't expose Spark's toPandas()\n", "        return g['df_daily']\n", "    if '_sqldf' in g:\n", "        return g['_sqldf'].toPandas()\n", "    if 'sdf_daily' in g:\n", "        return g['sdf_daily'].toPandas()\n", "    raise RuntimeError(\n", "        \"No input found for Cell 2. Define one in Cell 1:\\n\"\n", "        \"- df_daily (pandas)\\n- _sqldf (Spark from %sql)\\n- sdf_daily (Spark from Python)\"\n", "    )\n", "\n", "\n", "if __name__ == \"__main__\":\n", "    # Execute Cell 2 when this file is run in a notebook cell.\n", "    df_daily = _resolve_df_daily()\n", "    print(\"Cell 2 \u2014 df_daily shape:\", df_daily.shape)\n", "    summary = process_summary_inline(df_daily)\n", "    print(\"Cell 2 \u2014 summary shape:\", summary.shape)\n", "    # Publish and preview\n", "    globals()['summary'] = summary\n", "    # Try to publish a Spark temp view for cross-language (R) access as `summary_kpis`\n", "    try:\n", "        from pyspark.sql import SparkSession  # type: ignore\n", "        spark = SparkSession.builder.getOrCreate()\n", "        spark.createDataFrame(summary).createOrReplaceTempView(\"summary_kpis\")\n", "        print(\"Cell 2 \u2014 published Spark temp view: summary_kpis\")\n", "    except Exception as _e:\n", "        # Non-fatal if Spark not available\n", "        pass\n", "    try:\n", "        display(summary.head(5))  # type: ignore[name-defined]\n", "    except Exception:\n", "        try:\n", "            from IPython.display import display as _display  # type: ignore\n", "            _display(summary.head(5))\n", "        except Exception:\n", "            print(summary.head(5).to_string(index=False))\n"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["\"\"\"\n", "Cell 5 \u2014 MAC \u00d7 ARPMAC Run-rate Matrix\n", "\n", "Purpose\n", "- Compute a matrix of monthly MTX run-rate by combinations of MAC (Monthly Active Customers) and ARPMAC.\n", "- Visualize as a heatmap to identify target corridors.\n", "\n", "Data requirements\n", "- monthly_mtx_revenue (float)\n", "- mac (int) \u2014 monthly active customers\n", "- Optionally, provide candidate grids for mac_values and arpmac_values.\n", "\n", "Output\n", "- Matplotlib/Seaborn heatmap figure.\n", "\n", "Note: Wires to `summary` (Cell 2) if available to derive a grid around latest values.\n", "\"\"\"\n", "\n", "from __future__ import annotations\n", "\n", "from typing import Iterable, Tuple\n", "\n", "import pandas as pd\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "\n", "\n", "def ensure_theme() -> None:\n", "    sns.set_theme(style=\"whitegrid\", context=\"talk\", palette=\"crest\")\n", "\n", "\n", "def build_matrix(\n", "    mac_values: Iterable[int],\n", "    arpmac_values: Iterable[float],\n", ") -> pd.DataFrame:\n", "    data = {\"MAC\": list(mac_values)}\n", "    df = pd.DataFrame(data)\n", "    for a in arpmac_values:\n", "        df[f\"ARPMAC={a:.2f}\"] = df[\"MAC\"] * a\n", "    return df.set_index(\"MAC\")\n", "\n", "\n", "def to_annual(df_monthly: pd.DataFrame) -> pd.DataFrame:\n", "    return df_monthly * 12.0\n", "\n", "\n", "def plot_heatmap(\n", "    annual_matrix: pd.DataFrame,\n", "    title: str = \"MTX Run Rate (Annualized) \u2014 MAC \u00d7 ARPMAC\",\n", "    fmt: str = \".0f\",\n", "    cbar: bool = True,\n", "):\n", "    ensure_theme()\n", "    fig, ax = plt.subplots(figsize=(12, 7))\n", "    sns.heatmap(\n", "        annual_matrix,\n", "        annot=True,\n", "        fmt=fmt,\n", "        linewidths=0.5,\n", "        linecolor=\"white\",\n", "        cbar=cbar,\n", "        ax=ax,\n", "    )\n", "    ax.set_title(title)\n", "    ax.set_xlabel(\"ARPMAC\")\n", "    ax.set_ylabel(\"MAC\")\n", "    plt.tight_layout()\n", "    return fig, ax\n", "\n", "\n", "def _derive_grid_from_summary(summary: pd.DataFrame) -> Tuple[list[int], list[float]]:\n", "    s = summary.copy().sort_values(\"month_start\")\n", "    for c in (\"monthly_active_customers\", \"monthly_revenue\", \"month_start\"):\n", "        if c not in s.columns:\n", "            raise KeyError(f\"summary missing {c}\")\n", "    last = s.dropna(subset=[\"monthly_active_customers\", \"monthly_revenue\"]).tail(1)\n", "    if last.empty:\n", "        raise ValueError(\"summary has no monthly rows with required fields\")\n", "    mac0 = int(last[\"monthly_active_customers\"].iloc[0])\n", "    rev0 = float(last[\"monthly_revenue\"].iloc[0])\n", "    arpmac0 = rev0 / max(mac0, 1)\n", "    mac_values = [max(1, int(mac0 * m)) for m in [0.8, 0.9, 1.0, 1.2, 1.4, 1.6]]\n", "    arpmac_values = [max(0.01, round(arpmac0 * f, 2)) for f in [0.8, 0.9, 1.0, 1.2, 1.4, 1.6]]\n", "    return sorted(set(mac_values)), sorted(set(arpmac_values))\n", "\n", "\n", "def main() -> None:\n", "    try:\n", "        g = globals()\n", "        if \"summary\" in g:\n", "            mac_values, arpmac_values = _derive_grid_from_summary(g[\"summary\"])\n", "        else:\n", "            raise KeyError(\"summary not found; using defaults\")\n", "    except Exception:\n", "        mac_values = [1_000_000, 1_200_000, 1_500_000, 1_800_000, 2_160_000, 2_520_000, 2_880_000, 3_240_000, 3_600_000]\n", "        arpmac_values = [3.00, 3.60, 4.20, 4.83, 5.43, 5.97]\n", "\n", "    monthly_matrix = build_matrix(mac_values, arpmac_values)\n", "    annual_matrix = to_annual(monthly_matrix)\n", "    fig, _ = plot_heatmap(annual_matrix)\n", "    try:\n", "        plt.show()\n", "    except Exception:\n", "        fig.savefig(\"cell_5_mac_arpmac_matrix.png\", dpi=160)\n", "\n", "\n", "if __name__ == \"__main__\":\n", "    main()\n", "\n"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["\"\"\"\n", "Cell 6 \u2014 Period Retention (DoD, WoW, MoM)\n", "\n", "Scope\n", "- Customer retention: prior active customers returning (DoD/WoW/MoM)\n", "- Payer\u2192Payer retention: prior payers returning as payers (DoD/WoW/MoM)\n", "\n", "Notes\n", "- Uses precomputed rates from Cell 2 `summary` to avoid SQL changes.\n", "\"\"\"\n", "\n", "from __future__ import annotations\n", "\n", "import pandas as pd\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "from cell_style import ensure_theme, percent_axis\n", "\n", "\n", "def plot_series(df: pd.DataFrame, x: str, y: str, title: str, outfile: str) -> None:\n", "    ensure_theme()\n", "    plt.figure(figsize=(12, 6))\n", "    ax = sns.lineplot(data=df, x=x, y=y, marker=\"o\")\n", "    plt.title(title)\n", "    percent_axis(ax)\n", "    plt.tight_layout()\n", "    try:\n", "        plt.show()\n", "    except Exception:\n", "        plt.savefig(outfile, dpi=160)\n", "\n", "\n", "def main() -> None:\n", "    g = globals()\n", "    if \"summary\" not in g:\n", "        print(\"summary not found; run Cell 2 first.\")\n", "        return\n", "    s = g[\"summary\"].copy().sort_values(\"metric_date_dt\")\n", "    s[\"date\"] = pd.to_datetime(s[\"metric_date_dt\"]).dt.date\n", "\n", "    # Customers \u2014 DoD, WoW, MoM\n", "    cust_cols = [\n", "        (\"dod_customer_retention\", \"Customer Retention \u2014 Day over Day\", \"cell_6_cust_dod_retention.png\"),\n", "        (\"wow_customer_retention\", \"Customer Retention \u2014 Week over Week\", \"cell_6_cust_wow_retention.png\"),\n", "        (\"mom_customer_retention\", \"Customer Retention \u2014 Month over Month\", \"cell_6_cust_mom_retention.png\"),\n", "    ]\n", "    for col, title, outfile in cust_cols:\n", "        if col in s.columns:\n", "            plot_series(s, x=\"date\", y=col, title=title, outfile=outfile)\n", "        else:\n", "            print(\"Skipping customers retention:\", col, \"not found.\")\n", "\n", "    # Payers \u2014 DoD, WoW, MoM (payer\u2192payer)\n", "    payer_cols = [\n", "        (\"dod_payer_retention\", \"Payer Retention \u2014 Day over Day\", \"cell_6_payer_dod_retention.png\"),\n", "        (\"wow_payer_retention\", \"Payer Retention \u2014 Week over Week\", \"cell_6_payer_wow_retention.png\"),\n", "        (\"mom_payer_retention\", \"Payer Retention \u2014 Month over Month\", \"cell_6_payer_mom_retention.png\"),\n", "    ]\n", "    for col, title, outfile in payer_cols:\n", "        if col in s.columns:\n", "            plot_series(s, x=\"date\", y=col, title=title, outfile=outfile)\n", "        else:\n", "            print(\"Skipping payer retention:\", col, \"not found.\")\n", "\n", "\n", "if __name__ == \"__main__\":\n", "    main()\n", "\n"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["\"\"\"\n", "Cell 6 \u2014 Cohort Conversion by Horizon (D1/D7/D30/D60/D90)\n", "\n", "Purpose\n", "- Plot conversion curves by cohort using horizons available from Cell 1/2.\n", "- Serves as a proxy until explicit cohort-based retention by month-since-first-MTX is available.\n", "\n", "Data\n", "- Uses `summary` from Cell 2. Requires columns: `cohort_size`, `cohort_d{h}_converted`.\n", "\"\"\"\n", "\n", "from __future__ import annotations\n", "\n", "import pandas as pd\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "from cell_style import ensure_theme, percent_axis\n", "\n", "\n", "def build_cohort_horizon_rates(summary: pd.DataFrame) -> pd.DataFrame:\n", "    s = summary.copy()\n", "    if \"cohort_size\" not in s.columns:\n", "        raise KeyError(\"summary missing cohort_size; run Cell 1/2 with cohort rollup\")\n", "    s = s[s[\"cohort_size\"] > 0].copy()\n", "    s[\"cohort_month\"] = pd.to_datetime(s[\"metric_date_dt\"]).dt.to_period(\"M\").dt.to_timestamp()\n", "    horizons = [1, 7, 30, 60, 90]\n", "    out = {\"month\": s[\"cohort_month\"]}\n", "    for h in horizons:\n", "        conv_col = f\"cohort_d{h}_converted\"\n", "        if conv_col in s.columns:\n", "            rate = (s[conv_col] / s[\"cohort_size\"]).replace([float(\"inf\"), -float(\"inf\")], float(\"nan\"))\n", "            out[f\"d{h}_conversion\"] = rate\n", "    df = pd.DataFrame(out).drop_duplicates(\"month\").sort_values(\"month\")\n", "    return df\n", "\n", "\n", "def plot_horizon_rates(df: pd.DataFrame) -> None:\n", "    ensure_theme()\n", "    plt.figure(figsize=(12, 7))\n", "    value_cols = [c for c in df.columns if c != \"month\"]\n", "    for col in value_cols:\n", "        ax = sns.lineplot(data=df, x=\"month\", y=col, marker=\"o\", label=col)\n", "    plt.title(\"Cohort Conversion by Horizon (D1/D7/D30/D60/D90)\")\n", "    plt.xlabel(\"Cohort Month\")\n", "    plt.ylabel(\"Conversion Rate\")\n", "    percent_axis(ax)\n", "    plt.tight_layout()\n", "    try:\n", "        plt.show()\n", "    except Exception:\n", "        plt.savefig(\"cell_6_cohort_conversion_horizons.png\", dpi=160)\n", "\n", "\n", "def main() -> None:\n", "    g = globals()\n", "    if \"summary\" not in g:\n", "        print(\"summary not found; run Cell 2 first.\")\n", "        return\n", "    s = g[\"summary\"]\n", "    try:\n", "        df = build_cohort_horizon_rates(s)\n", "        if len(df.columns) <= 1:\n", "            print(\"No cohort horizon fields present; skipping chart.\")\n", "            return\n", "        plot_horizon_rates(df)\n", "    except Exception as e:\n", "        print(\"Skipping cohort horizon chart:\", e)\n", "\n", "\n", "if __name__ == \"__main__\":\n", "    main()\n", "\n"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["\"\"\"\n", "Cell 7 \u2014 Conversion Charts\n", "\n", "Charts\n", "- Period-based first-time conversion (monthly): new customers / new users in month\n", "- Cohort D7 conversion: fraction of cohort converting by day 7\n", "- Monthly conversion: unique payers / unique active players\n", "\n", "Data\n", "- Uses `summary` from Cell 2 if present. Falls back to placeholders otherwise.\n", "\"\"\"\n", "\n", "from __future__ import annotations\n", "\n", "import pandas as pd\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "from cell_style import ensure_theme, percent_axis\n", "\n", "\n", "def plot_time_series(df: pd.DataFrame, x: str, y: str, title: str, outfile: str) -> None:\n", "    ensure_theme()\n", "    plt.figure(figsize=(12, 6))\n", "    ax = sns.lineplot(data=df, x=x, y=y, marker=\"o\")\n", "    plt.title(title)\n", "    percent_axis(ax)\n", "    plt.tight_layout()\n", "    try:\n", "        plt.show()\n", "    except Exception:\n", "        plt.savefig(outfile, dpi=160)\n", "\n", "\n", "def _monthly_period_conversion_from_summary(summary: pd.DataFrame) -> pd.DataFrame:\n", "    s = summary.copy().sort_values(\"month_start\")\n", "    cols = [\"month_start\", \"monthly_new_users\", \"monthly_new_customers\"]\n", "    for c in cols:\n", "        if c not in s.columns:\n", "            raise KeyError(f\"summary missing {c}\")\n", "    m = s.groupby(\"month_start\").agg(\n", "        monthly_new_users=(\"monthly_new_users\", \"max\"),\n", "        monthly_new_customers=(\"monthly_new_customers\", \"max\"),\n", "    ).reset_index()\n", "    m[\"period_first_time_conversion\"] = (m[\"monthly_new_customers\"] / m[\"monthly_new_users\"]).replace([float(\"inf\"), -float(\"inf\")], float(\"nan\"))\n", "    return m[[\"month_start\", \"period_first_time_conversion\"]].rename(columns={\"month_start\": \"month\"})\n", "\n", "\n", "def _monthly_conversion_from_summary(summary: pd.DataFrame) -> pd.DataFrame:\n", "    s = summary.copy().sort_values(\"month_start\")\n", "    cols = [\"month_start\", \"monthly_payers\", \"monthly_active_users\"]\n", "    for c in cols:\n", "        if c not in s.columns:\n", "            raise KeyError(f\"summary missing {c}\")\n", "    m = s.groupby(\"month_start\").agg(\n", "        monthly_payers=(\"monthly_payers\", \"max\"),\n", "        monthly_active_users=(\"monthly_active_users\", \"max\"),\n", "    ).reset_index()\n", "    m[\"monthly_conversion\"] = (m[\"monthly_payers\"] / m[\"monthly_active_users\"]).replace([float(\"inf\"), -float(\"inf\")], float(\"nan\"))\n", "    return m[[\"month_start\", \"monthly_conversion\"]].rename(columns={\"month_start\": \"month\"})\n", "\n", "\n", "def _cohort_d7_from_summary(summary: pd.DataFrame) -> pd.DataFrame:\n", "    s = summary.copy()\n", "    if \"cohort_size\" not in s.columns or \"cohort_d7_converted\" not in s.columns:\n", "        raise KeyError(\"summary missing cohort fields\")\n", "    s = s[s[\"cohort_size\"] > 0].copy()\n", "    s[\"cohort_month\"] = pd.to_datetime(s[\"metric_date_dt\"]).dt.to_period(\"M\").dt.to_timestamp()\n", "    s[\"cohort_d7_conversion\"] = (s[\"cohort_d7_converted\"] / s[\"cohort_size\"]).replace([float(\"inf\"), -float(\"inf\")], float(\"nan\"))\n", "    c = s.sort_values(\"cohort_month\").drop_duplicates(\"cohort_month\")\n", "    return c[[\"cohort_month\", \"cohort_d7_conversion\"]].rename(columns={\"cohort_month\": \"month\"})\n", "\n", "\n", "def main() -> None:\n", "    g = globals()\n", "    if \"summary\" not in g:\n", "        print(\"summary not found; charts will not render. Run Cell 2 first.\")\n", "        return\n", "    s = g[\"summary\"]\n", "\n", "    try:\n", "        df_period = _monthly_period_conversion_from_summary(s)\n", "        plot_time_series(df_period, x=\"month\", y=\"period_first_time_conversion\", title=\"Period First-time Conversion (New Customers / New Users)\", outfile=\"cell_7_period_first_time_conversion.png\")\n", "    except Exception as e:\n", "        print(\"Skipping period first-time conversion:\", e)\n", "\n", "    try:\n", "        df_monthly_conv = _monthly_conversion_from_summary(s)\n", "        plot_time_series(df_monthly_conv, x=\"month\", y=\"monthly_conversion\", title=\"Monthly Conversion (Payers / Active Players)\", outfile=\"cell_7_monthly_conversion.png\")\n", "    except Exception as e:\n", "        print(\"Skipping monthly conversion:\", e)\n", "\n", "    try:\n", "        df_c7 = _cohort_d7_from_summary(s)\n", "        plot_time_series(df_c7, x=\"month\", y=\"cohort_d7_conversion\", title=\"Cohort D7 Conversion\", outfile=\"cell_7_cohort_d7_conversion.png\")\n", "    except Exception as e:\n", "        print(\"Skipping cohort D7 conversion:\", e)\n", "\n", "\n", "if __name__ == \"__main__\":\n", "    main()\n", "\n"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["\"\"\"\n", "Cell 8 \u2014 MTX vs Entitlement Mix (Monthly and LTD)\n", "\n", "Data\n", "- Prefers `summary` from Cell 2. Looks for columns to compute shares:\n", "  - Monthly: `monthly_total_revenue` and `monthly_mtx_revenue`; or `monthly_revenue` (MTX) plus entitlement fields if present.\n", "  - LTD (optional): `ltd_total_revenue` and `ltd_mtx_revenue`.\n", "\n", "Outputs\n", "- Line charts for monthly share and LTD share (if fields are available).\n", "\"\"\"\n", "\n", "from __future__ import annotations\n", "\n", "import pandas as pd\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "from cell_style import ensure_theme, percent_axis\n", "\n", "\n", "def compute_share(numer: pd.Series, denom: pd.Series) -> pd.Series:\n", "    return (numer / denom).clip(lower=0, upper=1)\n", "\n", "\n", "def plot_share(df: pd.DataFrame, x: str, y: str, title: str, outfile: str) -> None:\n", "    ensure_theme()\n", "    plt.figure(figsize=(12, 6))\n", "    ax = sns.lineplot(data=df, x=x, y=y, marker=\"o\")\n", "    plt.title(title)\n", "    percent_axis(ax)\n", "    plt.tight_layout()\n", "    try:\n", "        plt.show()\n", "    except Exception:\n", "        plt.savefig(outfile, dpi=160)\n", "\n", "\n", "def main() -> None:\n", "    g = globals()\n", "    if \"summary\" not in g:\n", "        print(\"summary not found; run Cell 2 first.\")\n", "        return\n", "    s = g[\"summary\"].copy().sort_values(\"month_start\")\n", "\n", "    total_col, mtx_col = None, None\n", "    if {\"monthly_total_revenue\", \"monthly_mtx_revenue\"}.issubset(s.columns):\n", "        total_col, mtx_col = \"monthly_total_revenue\", \"monthly_mtx_revenue\"\n", "    elif \"monthly_revenue\" in s.columns and \"monthly_entitlement_revenue\" in s.columns:\n", "        s[\"monthly_total_revenue\"] = s[\"monthly_revenue\"] + s[\"monthly_entitlement_revenue\"]\n", "        total_col, mtx_col = \"monthly_total_revenue\", \"monthly_revenue\"\n", "    else:\n", "        print(\"Skipping monthly mix: total revenue fields not found.\")\n", "\n", "    if total_col and mtx_col:\n", "        m = s.groupby(\"month_start\").agg(\n", "            total=(total_col, \"max\"),\n", "            mtx=(mtx_col, \"max\"),\n", "        ).reset_index()\n", "        m[\"mtx_share\"] = compute_share(m[\"mtx\"], m[\"total\"]) \n", "        plot_share(m.rename(columns={\"month_start\": \"month\"}), x=\"month\", y=\"mtx_share\", title=\"Monthly MTX Share of Total Revenue\", outfile=\"cell_8_monthly_mtx_share.png\")\n", "\n", "    if {\"ltd_total_revenue\", \"ltd_mtx_revenue\"}.issubset(s.columns):\n", "        l = s.sort_values(\"metric_date_dt\").tail(1)[[\"ltd_total_revenue\", \"ltd_mtx_revenue\"]]\n", "        share = compute_share(l[\"ltd_mtx_revenue\"], l[\"ltd_total_revenue\"]).iloc[0]\n", "        print(f\"LTD MTX share: {share:.2%}\")\n", "\n", "\n", "if __name__ == \"__main__\":\n", "    main()\n", "\n"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["\"\"\"\n", "Cell 9 \u2014 LTV Charts\n", "\n", "Charts (if data is available)\n", "- Entitlement LTV = ltd_entitlement_revenue / ltd_unique_new_players\n", "- MTX Payer LTV = ltd_mtx_revenue / ltd_unique_mtx_purchasers\n", "- Player MTX LTV = ltd_mtx_revenue / ltd_unique_players\n", "\n", "Note: If LTD fields are not available in `summary`, this cell will skip.\n", "\"\"\"\n", "\n", "from __future__ import annotations\n", "\n", "import pandas as pd\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "from cell_style import ensure_theme\n", "\n", "\n", "def plot_ltvs(df: pd.DataFrame) -> None:\n", "    ensure_theme()\n", "    plt.figure(figsize=(12, 6))\n", "    for col in [c for c in df.columns if c != \"month\"]:\n", "        sns.lineplot(data=df, x=\"month\", y=col, marker=\"o\", label=col)\n", "    plt.title(\"LTV Metrics Over Time\")\n", "    plt.legend()\n", "    plt.tight_layout()\n", "    try:\n", "        plt.show()\n", "    except Exception:\n", "        plt.savefig(\"cell_9_ltv_charts.png\", dpi=160)\n", "\n", "\n", "def main() -> None:\n", "    g = globals()\n", "    if \"summary\" not in g:\n", "        print(\"summary not found; run Cell 2 first.\")\n", "        return\n", "    s = g[\"summary\"].copy().sort_values(\"month_start\")\n", "\n", "    needed_any = [\n", "        {\"ltd_mtx_revenue\", \"ltd_unique_mtx_purchasers\"},\n", "        {\"ltd_mtx_revenue\", \"ltd_unique_players\"},\n", "        {\"ltd_entitlement_revenue\", \"ltd_unique_new_players\"},\n", "    ]\n", "    if not any(cols.issubset(s.columns) for cols in needed_any):\n", "        print(\"Skipping LTV charts: LTD fields not found in summary.\")\n", "        return\n", "\n", "    df = pd.DataFrame({\"month\": s[\"month_start\"].dropna().unique()})\n", "    df = df.sort_values(\"month\")\n", "\n", "    if {\"ltd_mtx_revenue\", \"ltd_unique_mtx_purchasers\"}.issubset(s.columns):\n", "        last = s.dropna(subset=[\"ltd_mtx_revenue\", \"ltd_unique_mtx_purchasers\"]).drop_duplicates(\"month_start\", keep=\"last\")\n", "        df = df.merge(\n", "            last[[\"month_start\", \"ltd_mtx_revenue\", \"ltd_unique_mtx_purchasers\"]].rename(columns={\"month_start\": \"month\"}),\n", "            on=\"month\", how=\"left\"\n", "        )\n", "        df[\"ltv_mtx_payer\"] = (df[\"ltd_mtx_revenue\"] / df[\"ltd_unique_mtx_purchasers\"]) \n", "\n", "    if {\"ltd_mtx_revenue\", \"ltd_unique_players\"}.issubset(s.columns):\n", "        last = s.dropna(subset=[\"ltd_mtx_revenue\", \"ltd_unique_players\"]).drop_duplicates(\"month_start\", keep=\"last\")\n", "        df = df.merge(\n", "            last[[\"month_start\", \"ltd_mtx_revenue\", \"ltd_unique_players\"]].rename(columns={\"month_start\": \"month\", \"ltd_mtx_revenue\": \"ltd_mtx_revenue_players\"}),\n", "            on=\"month\", how=\"left\"\n", "        )\n", "        df[\"ltv_player_mtx\"] = (df[\"ltd_mtx_revenue_players\"] / df[\"ltd_unique_players\"]) \n", "\n", "    if {\"ltd_entitlement_revenue\", \"ltd_unique_new_players\"}.issubset(s.columns):\n", "        last = s.dropna(subset=[\"ltd_entitlement_revenue\", \"ltd_unique_new_players\"]).drop_duplicates(\"month_start\", keep=\"last\")\n", "        df = df.merge(\n", "            last[[\"month_start\", \"ltd_entitlement_revenue\", \"ltd_unique_new_players\"]].rename(columns={\"month_start\": \"month\"}),\n", "            on=\"month\", how=\"left\"\n", "        )\n", "        df[\"ltv_entitlement\"] = (df[\"ltd_entitlement_revenue\"] / df[\"ltd_unique_new_players\"]) \n", "\n", "    value_cols = [c for c in df.columns if c != \"month\"]\n", "    keep = [c for c in value_cols if df[c].notna().any()]\n", "    if not keep:\n", "        print(\"No LTV series with data; skipping chart.\")\n", "        return\n", "    plot_ltvs(df[[\"month\"] + keep])\n", "\n", "\n", "if __name__ == \"__main__\":\n", "    main()\n", "\n"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["\"\"\"\n", "Cell 10 \u2014 Activity Mix: Customers as Share of Active Players\n", "\n", "Chart\n", "- Customers / Active Players (monthly), using `summary` from Cell 2.\n", "\"\"\"\n", "\n", "from __future__ import annotations\n", "\n", "import pandas as pd\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "from cell_style import ensure_theme, percent_axis\n", "\n", "\n", "def plot_customers_share(df: pd.DataFrame) -> None:\n", "    ensure_theme()\n", "    plt.figure(figsize=(12, 6))\n", "    ax = sns.lineplot(data=df, x=\"month\", y=\"customers_share\", marker=\"o\")\n", "    plt.title(\"Customers Share of Active Players\")\n", "    percent_axis(ax)\n", "    plt.tight_layout()\n", "    try:\n", "        plt.show()\n", "    except Exception:\n", "        plt.savefig(\"cell_10_activity_mix_customers_share.png\", dpi=160)\n", "\n", "\n", "def main() -> None:\n", "    g = globals()\n", "    if \"summary\" not in g:\n", "        print(\"summary not found; run Cell 2 first.\")\n", "        return\n", "    s = g[\"summary\"].copy()\n", "    cols = [\"month_start\", \"monthly_active_customers\", \"monthly_active_users\"]\n", "    for c in cols:\n", "        if c not in s.columns:\n", "            print(\"Skipping activity mix: missing\", c)\n", "            return\n", "    m = s.groupby(\"month_start\").agg(\n", "        mac=(\"monthly_active_customers\", \"max\"),\n", "        mau=(\"monthly_active_users\", \"max\"),\n", "    ).reset_index()\n", "    m = m.rename(columns={\"month_start\": \"month\"})\n", "    m[\"customers_share\"] = (m[\"mac\"] / m[\"mau\"]).clip(lower=0, upper=1)\n", "    plot_customers_share(m[[\"month\", \"customers_share\"]])\n", "\n", "\n", "if __name__ == \"__main__\":\n", "    main()\n", "\n"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["\"\"\"\n", "Cell 11 \u2014 VC Price Realization vs. List\n", "\n", "Effective VC price = realized_mtx_vc_revenue / total_vc_units_consumed_at_list_price\n", "Optionally adjust numerator by excluding discounts or including net-of-fees.\n", "Currently optional \u2014 may be unused if VC pricing is out of scope.\n", "\"\"\"\n", "\n", "from __future__ import annotations\n", "\n", "import pandas as pd\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "from cell_style import ensure_theme\n", "\n", "\n", "def plot_price_realization(df: pd.DataFrame) -> None:\n", "    ensure_theme()\n", "    plt.figure(figsize=(12, 6))\n", "    sns.lineplot(data=df, x=\"month\", y=\"effective_price\", marker=\"o\", label=\"Effective\")\n", "    if \"list_price\" in df.columns:\n", "        sns.lineplot(data=df, x=\"month\", y=\"list_price\", marker=\"o\", label=\"List\")\n", "    plt.title(\"VC Price Realization vs. List\")\n", "    plt.legend()\n", "    plt.tight_layout()\n", "    try:\n", "        plt.show()\n", "    except Exception:\n", "        plt.savefig(\"cell_11_vc_price_realization.png\", dpi=160)\n", "\n", "\n", "def main() -> None:\n", "    # Placeholder; requires VC ledger mapping. Skipping by default.\n", "    pass\n", "\n", "\n", "if __name__ == \"__main__\":\n", "    main()\n", "\n"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["\"\"\"\n", "Cell 12 \u2014 Dormancy Rate\n", "\n", "Share of customers purchasing in the month; complement suggests dormancy.\n", "Metric: monthly_payers / monthly_active_customers (from `summary`).\n", "\"\"\"\n", "\n", "from __future__ import annotations\n", "\n", "import pandas as pd\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "from cell_style import ensure_theme, percent_axis\n", "\n", "\n", "def plot_dormancy(df: pd.DataFrame) -> None:\n", "    ensure_theme()\n", "    plt.figure(figsize=(12, 6))\n", "    ax = sns.lineplot(data=df, x=\"month\", y=\"purchase_rate\", marker=\"o\")\n", "    plt.title(\"Customers Purchasing in Month (Dormancy Complement)\")\n", "    percent_axis(ax)\n", "    plt.tight_layout()\n", "    try:\n", "        plt.show()\n", "    except Exception:\n", "        plt.savefig(\"cell_12_dormancy_rate.png\", dpi=160)\n", "\n", "\n", "def main() -> None:\n", "    g = globals()\n", "    if \"summary\" not in g:\n", "        print(\"summary not found; run Cell 2 first.\")\n", "        return\n", "    s = g[\"summary\"].copy()\n", "    cols = [\"month_start\", \"monthly_payers\", \"monthly_active_customers\"]\n", "    for c in cols:\n", "        if c not in s.columns:\n", "            print(\"Skipping dormancy: missing\", c)\n", "            return\n", "    m = s.groupby(\"month_start\").agg(\n", "        monthly_payers=(\"monthly_payers\", \"max\"),\n", "        mac=(\"monthly_active_customers\", \"max\"),\n", "    ).reset_index().rename(columns={\"month_start\": \"month\"})\n", "    m[\"purchase_rate\"] = (m[\"monthly_payers\"] / m[\"mac\"]).clip(lower=0, upper=1)\n", "    plot_dormancy(m[[\"month\", \"purchase_rate\"]])\n", "\n", "\n", "if __name__ == \"__main__\":\n", "    main()\n", "\n"], "outputs": [], "metadata": {}}], "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"version": "3", "name": "python"}}, "nbformat": 4}